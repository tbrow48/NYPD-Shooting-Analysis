---
title: "NYPD COVID Shooting"
author: "OB"
date: "2024-10-08"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

## 1. Importing Data

First we install one of R's most important libraries (tidyverse)
```{r, results = "hide", message=FALSE}
library(tidyverse)
```

Next, we obtain the url that we will be downloading our NYPD shooting data from and extract it into a df using read_csv from the tidyverse library

```{r, results = "hide", message=FALSE}
url_in <- "https://data.cityofnewyork.us/api/views/833y-fsy8/rows.csv?accessType=DOWNLOAD"
nypd_shoot <- read_csv(url_in)
```
We have now imported and stored our data in a variable.

## 2. Tidying and Transforming Data

Let's call on our data to see what it looks like to have a general understanding of variables we would need to change or affect in our tidying and transformation process.

```{r}
nypd_shoot
```

I have decided to remove all the location based columns. Analysis will be done by borough/precinct. Then, load the lubridate library and change the occur_date column to type date.

```{r}
nypd_shoot <- nypd_shoot %>% select(-c(Latitude, Longitude, X_COORD_CD, Y_COORD_CD, Lon_Lat))
library(lubridate)
nypd_shoot$OCCUR_DATE <- mdy(nypd_shoot$OCCUR_DATE)
summary(nypd_shoot)
```

## 3. Visualization and Model(s)

The first visualization I am making is what percentage of shootings take place by Borough. 

```{r}
 borough_counts <- nypd_shoot %>%
     group_by(BORO) %>%
     summarize(count = n())

borough_counts <- borough_counts %>%
      mutate(percentage = count / sum(count) * 100)

ggplot(borough_counts, aes(x = BORO, y = count, fill = BORO)) +
      geom_bar(stat = "identity") +
      geom_text(aes(label = paste0(round(percentage, 0), "%")), vjust = -0.5) + 
      labs(title = "Percentage of Shooting Incidents by Borough 2006 - 2023",
           x = "Borough",
           y = "Number of Incidents") +
      theme_minimal()
```

The next visualization I make is one that shows what time these shootings occur.

```{r}
classify_time <- function(time) {
      hour <- as.numeric(format(time, "%H"))  # Extract hour as numeric
      
      if (hour >= 5 & hour < 12) {
          return("Morning")
      } else if (hour >= 12 & hour < 17) {
          return("Afternoon")
      } else if (hour >= 17 & hour < 21) {
          return("Evening")
      } else {
          return("Night")
      }
}

nypd_shoot <- nypd_shoot %>%
     mutate(OCCUR_TIME = as.POSIXct(OCCUR_TIME, format = "%H:%M:%S", tz = "UTC"))
nypd_shoot <- nypd_shoot %>%
     mutate(Time_Period = sapply(OCCUR_TIME, classify_time))

time_counts <- nypd_shoot %>%
           group_by(Time_Period) %>%
           summarize(count = n())
time_counts <- time_counts %>%
           mutate(percentage = count / sum(count) * 100)

ggplot(time_counts, aes(x = Time_Period, y = count, fill = Time_Period)) +
     geom_bar(stat = "identity") +
     geom_text(aes(label = paste0(round(percentage, 0), "%")), vjust = -0.5) + 
     labs(
         title = "Percentage of Shooting Incidents by Time of Day",
         x = "Time Period",
         y = "Number of Incidents"
     ) +
     theme_minimal()
```


Using a linear regression model to showcase relationships between boroughs and the times of night that shootings occur.

```{r, results = "hide", message=FALSE}
incident_counts <- nypd_shoot %>%
      group_by(OCCUR_DATE, BORO, Time_Period) %>%
      summarize(incident_count = n())
```

```{r}
lm_model <- lm(incident_count ~ BORO + OCCUR_DATE + Time_Period, data = incident_counts)

summary(lm_model)
```

### **Three Key Insights that can be drawn from the data:**

 1. Shootings are statistically more likely to occur at night
 2. Shootings are decreasing over time, a possible decline in gun violence
 3. Manhattan, Queens, and Staten Island are less likely to havve shooting incidents

## 4. Ethics/Bias Analysis

An analysis that I decided not to do was to look into a relationship for ethnicity. As data scientists we must ensure that the insights we produce and share isn't harmful.